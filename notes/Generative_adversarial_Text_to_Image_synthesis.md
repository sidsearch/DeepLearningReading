* Novel, deep architecture and GAN formulation to effectively bridge the advances in text and image model, translating visual concepts from characters to pixels.
* Demostrate capability of the model to generate plausible images of birds and flowers from detailed text descriptions
* Distinction from conditional GAN is that this model conditions on text descriptions instead of class labels
* end to end differentiable architecture from character to pixel value
* GANs consist of a generator and discriminator which are in a two player minimax game. D tried distinguish real training data from synthetic data and G tries to fool the D.
* to obtain a visually discriminative vector representation of text descriptions, Reed et al proposed that deep Conv and Recurrent Text encoders that learn a correspondence function with images.The text classifier is induced by learned correspondence function f(t) trained by optimizing. 
